{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1de88a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Functions (adapted) ---\n",
    "\n",
    "# Re-define the plotting functions to accept PyTorch model outputs\n",
    "\n",
    "# --- Helper Functions (from your provided code) ---\n",
    "def exp_decay(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=[\"Background\", \"Signal\"]):\n",
    "    \"\"\"\n",
    "    Plot a normalized confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues, colorbar=False, values_format=\".2f\")\n",
    "    ax.set_title(\"Normalized Confusion Matrix\")\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_binned_background_shape(\n",
    "    probs, # Pass probabilities directly now\n",
    "    y_true, # Pass true labels\n",
    "    mass_unscaled, # Pass the unscaled mass\n",
    "    weight,\n",
    "    bins=np.linspace(110, 160, 80),\n",
    "    score_bins=[(0.00, 0.34), (0.34, 0.68), (0.68, 0.9), (0.9, 1.0)],\n",
    "    colors=[\"blue\", \"orange\", \"green\", \"red\"],\n",
    "    higgs_mass=125\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot binned dimuon mass distribution for background events,\n",
    "    separated by classifier score bins, with exponential background fit.\n",
    "    Now takes probabilities and unscaled mass directly.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure proper array types\n",
    "    y_true = np.asarray(y_true)\n",
    "    weight = np.asarray(weight)\n",
    "    probs = np.asarray(probs)\n",
    "    mass_unscaled = np.asarray(mass_unscaled)\n",
    "\n",
    "\n",
    "    # Select background events\n",
    "    mask_bkg = y_true == 0\n",
    "    scores = probs[mask_bkg]\n",
    "    masses = mass_unscaled[mask_bkg]\n",
    "    weights_bkg = weight[mask_bkg]\n",
    "\n",
    "    # Setup bins and labels\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "    labels = [f\"{low:.2f} ≤ Score < {high:.2f}\" for (low, high) in score_bins]\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "\n",
    "    # Plot histograms by classifier score\n",
    "    for (low, high), color, label in zip(score_bins, colors, labels):\n",
    "        mask = (scores >= low) & (scores < high)\n",
    "        hist, _ = np.histogram(masses[mask], bins=bins, weights=weights_bkg[mask], density=True)\n",
    "        plt.step(bin_centers, hist, where=\"mid\", color=color, label=label)\n",
    "\n",
    "    # Full background shape and fit\n",
    "    hist_all, _ = np.histogram(masses, bins=bins, weights=weights_bkg, density=True)\n",
    "    try:\n",
    "        # Filter out zeros from hist_all for fitting if necessary\n",
    "        valid_indices = hist_all > 0\n",
    "        popt, _ = curve_fit(exp_decay, bin_centers[valid_indices], hist_all[valid_indices], p0=(1, 0.1, 0))\n",
    "        smoothed = exp_decay(bin_centers, *popt)\n",
    "        plt.plot(bin_centers, smoothed, 'k--', label=\"Fitted Background Shape\")\n",
    "    except RuntimeError:\n",
    "        print(\"⚠️ Background fit failed. Skipping fit curve.\")\n",
    "    except ValueError as e:\n",
    "         print(f\"⚠️ Background fit failed due to ValueError: {e}. Skipping fit curve.\")\n",
    "\n",
    "\n",
    "    # Higgs mass line\n",
    "    plt.axvline(higgs_mass, color=\"gray\", linestyle=\":\", label=\"Higgs Mass\")\n",
    "\n",
    "    # Final styling\n",
    "    plt.xlabel(r\"$M_{\\mu\\mu}$ [GeV]\")\n",
    "    plt.ylabel(\"Fraction of events\")\n",
    "    plt.title(\"Background Shape by Classifier Score\")\n",
    "    plt.legend(title=\"Score Bins\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efeb14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, columns, tree_name=\"tree_Hmumu\"):\n",
    "    \"\"\"\n",
    "    Load data from a ROOT file using uproot.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = uproot.open(file_path)[tree_name]\n",
    "        df = tree.arrays(columns, library=\"pd\")\n",
    "        # Consider if sampling is always desired or should be a parameter\n",
    "        df_sampled = df.sample(frac=0.05, random_state=42)  # Added random_state for reproducibility\n",
    "        # For now, using the full dataset as frac=0.1 might be too small for robust training\n",
    "        return df_sampled\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {file_path}: {e}\")\n",
    "        print(\"Please ensure the ROOT files are in the correct path and uproot is installed.\")\n",
    "        # Return empty DataFrame or raise to stop execution\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def prepare_data(background_df, signal_df, mass_column=\"Muons_Minv_MuMu_Fsr\", shuffle=True):\n",
    "    \"\"\"\n",
    "    Combine background and signal datasets, shuffle, and split into features, labels, weights, and mass.\n",
    "    \"\"\"\n",
    "    if background_df.empty or signal_df.empty:\n",
    "        print(\"One or both dataframes are empty. Cannot prepare data.\")\n",
    "        # Return empty tuples to signal failure\n",
    "        return pd.DataFrame(), pd.Series(dtype=\"float64\"), pd.Series(dtype=\"float64\"), np.array([])\n",
    "\n",
    "    df = pd.concat([background_df, signal_df], ignore_index=True)\n",
    "\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    x = df.drop([\"Binary_Target\", \"weight\", mass_column], axis=1)\n",
    "    y = df[\"Binary_Target\"]\n",
    "    mass = df[mass_column]\n",
    "    weight = df[\"weight\"].to_numpy()\n",
    "\n",
    "    y = y.to_numpy()\n",
    "    mass = mass.to_numpy()\n",
    "\n",
    "    return x, y, mass, weight\n",
    "\n",
    "\n",
    "def split_and_scale(X, y, mass, weight, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the dataset and apply standard scaling to features and mass separately.\n",
    "    \"\"\"\n",
    "    if X.empty:\n",
    "        print(\"Input feature DataFrame X is empty in split_and_scale. Cannot proceed.\")\n",
    "        # Return dummy values or raise an error\n",
    "        return (None,) * 10 + ([],)  # Match number of return values\n",
    "\n",
    "    X_train, X_test, y_train, y_test, mass_train, mass_test, weight_train, weight_test = (\n",
    "        train_test_split(X, y, mass, weight, test_size=test_size, random_state=42, stratify=y)\n",
    "    )\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = feature_scaler.transform(X_test)\n",
    "\n",
    "    mass_scaler = StandardScaler()\n",
    "    mass_train_scaled = mass_scaler.fit_transform(mass_train.reshape(-1, 1)).flatten()\n",
    "    mass_test_scaled = mass_scaler.transform(mass_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "    mass_train_tensor = torch.tensor(mass_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "    mass_test_tensor = torch.tensor(mass_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "    weight_train_tensor = torch.tensor(weight_train, dtype=torch.float32)\n",
    "    weight_test_tensor = torch.tensor(weight_test, dtype=torch.float32)\n",
    "\n",
    "    return (\n",
    "        X_train_tensor,\n",
    "        X_test_tensor,\n",
    "        y_train_tensor,\n",
    "        y_test_tensor,\n",
    "        mass_train_tensor,\n",
    "        mass_test_tensor,\n",
    "        weight_train_tensor,\n",
    "        weight_test_tensor,\n",
    "        feature_scaler,\n",
    "        mass_scaler,\n",
    "        X.columns.tolist(),\n",
    "    )  # Return feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426abaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_clf, hidden_dim_clf_2, output_dim_clf=1, dropout_rate=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim_clf)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim_clf, hidden_dim_clf_2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(hidden_dim_clf_2, output_dim_clf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1_clf = self.relu1(self.fc1(x))\n",
    "        h1_clf_dropped = self.dropout1(h1_clf)\n",
    "        h2_clf = self.relu2(self.fc2(h1_clf_dropped))\n",
    "        h2_clf_dropped = self.dropout2(h2_clf)\n",
    "        # The adversary will receive h1_clf (the \"raw\" activated hidden state)\n",
    "        # The classifier's path to output uses dropout on this hidden state\n",
    "        logits = self.fc3(h2_clf_dropped)\n",
    "        return logits, h2_clf_dropped  # Return hidden layer for adversary\n",
    "\n",
    "\n",
    "class Adversary(nn.Module):\n",
    "    def __init__(self, input_dim_adv, hidden_dim_adv, output_dim_adv=1):\n",
    "        super(Adversary, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim_adv, hidden_dim_adv)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Optional: add dropout to adversary too if it's too strong or overfits\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(hidden_dim_adv, output_dim_adv)\n",
    "\n",
    "    def forward(self, h_from_classifier):\n",
    "        h_adv = self.relu(self.fc1(h_from_classifier))\n",
    "        h_adv = self.dropout(h_adv)\n",
    "        mass_prediction = self.fc2(h_adv)\n",
    "        return mass_prediction\n",
    "\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_adversarial_debiasing(\n",
    "    classifier,\n",
    "    adversary,\n",
    "    train_loader,\n",
    "    optimizer_clf,\n",
    "    optimizer_adv,\n",
    "    criterion_clf,\n",
    "    criterion_adv,\n",
    "    num_epochs,\n",
    "    adversary_loss_weight,\n",
    "    device,\n",
    "    debias=True,\n",
    "):\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(\n",
    "        f\"Debiasing active: {debias}, Adversary loss weight: {adversary_loss_weight if debias else 'N/A'}\"\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        classifier.train()\n",
    "        if debias:\n",
    "            adversary.train()\n",
    "\n",
    "        total_clf_loss_epoch = 0\n",
    "        total_adv_loss_epoch = 0\n",
    "        total_clf_task_loss_epoch = 0  # For monitoring main task performance\n",
    "\n",
    "        for batch_idx, (features, labels, mass_targets) in enumerate(train_loader):\n",
    "            features, labels, mass_targets = (\n",
    "                features.to(device),\n",
    "                labels.to(device),\n",
    "                mass_targets.to(device),\n",
    "            )\n",
    "\n",
    "            # --- Step 1: Train Adversary (if debiasing is active) ---\n",
    "            if debias:\n",
    "                optimizer_adv.zero_grad()\n",
    "                # Get hidden representation from classifier (don't track gradients for classifier here)\n",
    "                with torch.no_grad():  # Ensure classifier weights are not updated based on this\n",
    "                    _, hidden_rep_for_adv = classifier(features)\n",
    "\n",
    "                # Adversary predicts mass from the detached hidden representation\n",
    "                mass_pred_by_adv = adversary(\n",
    "                    hidden_rep_for_adv.detach()\n",
    "                )  # Detach again just to be sure\n",
    "                loss_adv = criterion_adv(mass_pred_by_adv, mass_targets)\n",
    "                loss_adv.backward()\n",
    "                optimizer_adv.step()\n",
    "                total_adv_loss_epoch += loss_adv.item()\n",
    "\n",
    "            # --- Step 2: Train Classifier ---\n",
    "            optimizer_clf.zero_grad()\n",
    "            clf_logits, hidden_rep_for_fooling = classifier(features)\n",
    "\n",
    "            # Classifier's primary task loss\n",
    "            loss_clf_task = criterion_clf(clf_logits, labels)\n",
    "            total_clf_task_loss_epoch += loss_clf_task.item()\n",
    "\n",
    "            if debias:\n",
    "                # Classifier tries to fool the adversary\n",
    "                # Adversary's weights are fixed here (no optimizer_adv.step())\n",
    "                # Gradients will flow back from this loss into the classifier\n",
    "                mass_pred_by_adv_for_fooling = adversary(hidden_rep_for_fooling)  # NO .detach()\n",
    "                loss_adv_for_fooling = criterion_adv(mass_pred_by_adv_for_fooling, mass_targets)\n",
    "\n",
    "                # Classifier wants to MAXIMIZE adversary's loss,\n",
    "                # so we SUBTRACT it from classifier's objective (or add negative)\n",
    "                total_loss_for_clf_update = (\n",
    "                    loss_clf_task - adversary_loss_weight * loss_adv_for_fooling\n",
    "                )\n",
    "            else:\n",
    "                total_loss_for_clf_update = loss_clf_task\n",
    "\n",
    "            total_loss_for_clf_update.backward()\n",
    "            optimizer_clf.step()\n",
    "            total_clf_loss_epoch += total_loss_for_clf_update.item()\n",
    "\n",
    "        avg_clf_loss = total_clf_loss_epoch / len(train_loader)\n",
    "        avg_clf_task_loss = total_clf_task_loss_epoch / len(train_loader)\n",
    "        if debias:\n",
    "            avg_adv_loss = total_adv_loss_epoch / len(train_loader)\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{num_epochs} | Avg Clf Loss: {avg_clf_loss:.4f} (Task: {avg_clf_task_loss:.4f}) | Avg Adv Loss: {avg_adv_loss:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{num_epochs} | Avg Clf Loss: {avg_clf_loss:.4f} (Task: {avg_clf_task_loss:.4f})\"\n",
    "            )\n",
    "\n",
    "    print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "df457259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "Preparing data...\n",
      "Splitting and scaling data...\n",
      "Starting training for 25 epochs...\n",
      "Debiasing active: True, Adversary loss weight: 0.5\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m criterion_adv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# 5. Train\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[43mtrain_adversarial_debiasing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43madversary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madversary_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_clf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_adv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion_clf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_adv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43madversary_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mADVERSARY_LOSS_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEBIAS_TRAINING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model and generating plots...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m classifier_model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[80], line 96\u001b[0m, in \u001b[0;36mtrain_adversarial_debiasing\u001b[1;34m(classifier, adversary, train_loader, optimizer_clf, optimizer_adv, criterion_clf, criterion_adv, num_epochs, adversary_loss_weight, device, debias)\u001b[0m\n\u001b[0;32m     93\u001b[0m clf_logits, hidden_rep_for_fooling \u001b[38;5;241m=\u001b[39m classifier(features)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Classifier's primary task loss\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m loss_clf_task \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion_clf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m total_clf_task_loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_clf_task\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debias:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Classifier tries to fool the adversary\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Adversary's weights are fixed here (no optimizer_adv.step())\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Gradients will flow back from this loss into the classifier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:720\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3165\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m   3163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m-> 3165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "COLUMNS = [\n",
    "    \"Jets_PT_Lead\",\n",
    "    \"Jets_PT_Sub\",\n",
    "    \"Jets_Phi_Lead\",\n",
    "    \"Jets_Phi_Sub\",\n",
    "    \"Jets_E_Lead\",\n",
    "    \"Jets_E_Sub\",\n",
    "    \"Jets_Eta_Lead\",\n",
    "    \"Jets_Eta_Sub\",\n",
    "    \"Muons_PT_Lead\",\n",
    "    \"Muons_PT_Sub\",\n",
    "    \"Muons_Phi_Lead\",\n",
    "    \"Muons_Phi_Sub\",\n",
    "    \"Muons_Eta_Lead\",\n",
    "    \"Muons_Eta_Sub\",\n",
    "    \"Muons_Minv_MuMu_Fsr\",  # Mass column\n",
    "    \"weight\",\n",
    "    \"Binary_Target\",\n",
    "]\n",
    "MASS_COLUMN_NAME = \"Muons_Minv_MuMu_Fsr\"\n",
    "# Adjust these paths to your actual file locations\n",
    "BACKGROUND_FILE = \"./../Fairness data/Background.root\"  # Example path\n",
    "SIGNAL_FILE = \"./../Fairness data/Signal.root\"  # Example path\n",
    "\n",
    "BATCH_SIZE = 128  # Increased from 16 for potentially more stable gradients\n",
    "LEARNING_RATE_CLF = 1e-2\n",
    "LEARNING_RATE_ADV = 1e-2\n",
    "NUM_EPOCHS = 25  # As in the original TF code\n",
    "CLF_HIDDEN_UNITS = 64  # As in the original TF \n",
    "CLF_HIDDEN_UNITS2 = 32  # As in the original TF \n",
    "ADV_HIDDEN_UNITS = 32  # A reasonable choice for the adversary's complexity\n",
    "ADVERSARY_LOSS_WEIGHT = 0.5  # Hyperparameter for debiasing strength\n",
    "DEBIAS_TRAINING = True  # Set to False to train a standard classifier\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "background_df = load_data(BACKGROUND_FILE, COLUMNS)\n",
    "signal_df = load_data(SIGNAL_FILE, COLUMNS)\n",
    "\n",
    "if background_df.empty or signal_df.empty:\n",
    "    print(\"Failed to load data. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Prepare Data\n",
    "print(\"Preparing data...\")\n",
    "x_val, y_val, mass_val, weight_val = prepare_data(\n",
    "    background_df, signal_df, mass_column=MASS_COLUMN_NAME\n",
    ")\n",
    "\n",
    "if x_val.empty:\n",
    "    print(\"Failed to prepare data (x_val is empty). Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# 3. Split and Scale Data\n",
    "print(\"Splitting and scaling data...\")\n",
    "(\n",
    "    X_train_tensor,\n",
    "    X_test_tensor,\n",
    "    y_train_tensor,\n",
    "    y_test_tensor,\n",
    "    mass_train_tensor,\n",
    "    mass_test_tensor,\n",
    "    weight_train_tensor,\n",
    "    weight_test_tensor,\n",
    "    feature_scaler,\n",
    "    mass_scaler,\n",
    "    feature_names,\n",
    ") = split_and_scale(x_val, y_val, mass_val, weight_val)\n",
    "\n",
    "if X_train_tensor is None:\n",
    "    print(\"Failed to split and scale data. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, mass_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor, mass_test_tensor) # For evaluation later\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 4. Initialize Models, Optimizers, Criteria\n",
    "input_dim_clf = X_train_tensor.shape[1]\n",
    "\n",
    "classifier_model = Classifier(input_dim=input_dim_clf, hidden_dim_clf=CLF_HIDDEN_UNITS, hidden_dim_clf_2=CLF_HIDDEN_UNITS2).to(\n",
    "    device\n",
    ")\n",
    "# Adversary input dimension is the classifier's hidden layer dimension\n",
    "adversary_model = Adversary(input_dim_adv=CLF_HIDDEN_UNITS2, hidden_dim_adv=ADV_HIDDEN_UNITS).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "optimizer_clf = optim.Adam(classifier_model.parameters(), lr=LEARNING_RATE_CLF)\n",
    "optimizer_adv = optim.Adam(adversary_model.parameters(), lr=LEARNING_RATE_ADV)\n",
    "\n",
    "# Loss for classifier (binary classification)\n",
    "criterion_clf = nn.BCEWithLogitsLoss()\n",
    "# Loss for adversary (mass prediction - regression)\n",
    "criterion_adv = nn.MSELoss()\n",
    "\n",
    "# 5. Train\n",
    "train_adversarial_debiasing(\n",
    "    classifier=classifier_model,\n",
    "    adversary=adversary_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer_clf=optimizer_clf,\n",
    "    optimizer_adv=optimizer_adv,\n",
    "    criterion_clf=criterion_clf,\n",
    "    criterion_adv=criterion_adv,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    adversary_loss_weight=ADVERSARY_LOSS_WEIGHT,\n",
    "    device=device,\n",
    "    debias=DEBIAS_TRAINING,\n",
    ")\n",
    "\n",
    "print(\"Evaluating model and generating plots...\")\n",
    "\n",
    "classifier_model.eval()\n",
    "adversary_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    test_logits, test_hidden_rep = classifier_model(X_test_tensor.to(device))\n",
    "    test_probs = torch.sigmoid(test_logits).cpu().numpy().flatten()\n",
    "    test_labels = y_test_tensor.cpu().numpy().flatten()\n",
    "    weight_np = weight_test_tensor.cpu().numpy().flatten()\n",
    "\n",
    "    # Inverse transform the mass back to original scale\n",
    "    unscaled_mass_test = mass_scaler.inverse_transform(\n",
    "        mass_test_tensor.cpu().numpy().reshape(-1, 1)\n",
    "    ).flatten()\n",
    "\n",
    "    # Plot: Confusion Matrix\n",
    "    test_preds = (test_probs > 0.5).astype(int)\n",
    "    plot_confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "    # Plot: Binned Background Shape\n",
    "    plot_binned_background_shape(\n",
    "        probs=test_probs,\n",
    "        y_true=test_labels,\n",
    "        mass_unscaled=unscaled_mass_test,\n",
    "        weight=weight_np\n",
    "    )\n",
    "\n",
    "    if DEBIAS_TRAINING:\n",
    "        mass_predictions_adv_test = adversary_model(test_hidden_rep)\n",
    "        test_adv_loss = criterion_adv(\n",
    "            mass_predictions_adv_test,\n",
    "            mass_test_tensor.to(device)\n",
    "        )\n",
    "        print(f\"Adversary MSE on test set: {test_adv_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98d06be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversary MSE on test set: 0.8110\n"
     ]
    }
   ],
   "source": [
    "adversary_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits, test_hidden_rep = classifier_model(X_test_tensor.to(device))\n",
    "    test_predictions = torch.sigmoid(test_logits)\n",
    "    # Calculate accuracy, AUC for classifier\n",
    "\n",
    "    if DEBIAS_TRAINING:\n",
    "        mass_predictions_adv_test = adversary_model(test_hidden_rep)\n",
    "        unscaled_mass_test = mass_scaler.inverse_transform(\n",
    "            mass_test_tensor.cpu().numpy().reshape(-1, 1)\n",
    "        ).flatten()\n",
    "        unscaled_mass_test = unscaled_mass_test[unscaled_mass_test < 200]\n",
    "        plt.hist(unscaled_mass_test, bins=25)\n",
    "        plt.show()\n",
    "        # Calculate MSE for adversary on test set\n",
    "        test_adv_loss = criterion_adv(mass_predictions_adv_test, mass_test_tensor.to(device))\n",
    "        print(f\"Adversary MSE on test set: {test_adv_loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
